{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import functools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create record files\n",
    "\n",
    "dirs = 'record/noise_0.8_iteration_5_cleansize_50_add_1000/test1/'\n",
    "if not os.path.exists(dirs):\n",
    "    os.makedirs(dirs)\n",
    "\n",
    "file_setting = open(dirs + 'file_setting.txt', 'a+')\n",
    "file_additional_data = open(dirs + 'file_additional_data.txt', 'a+')\n",
    "file_teacher = open(dirs + 'file_teacher.txt', 'a+')\n",
    "file_student = open(dirs + 'file_student.txt', 'a+')\n",
    "file_benchmark = open(dirs + 'file_benchmark.txt', 'a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from CIFAR10\n",
    "def load_data(clean_data_size):\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "\n",
    "    # transform labels to one-hot vectors\n",
    "    y_train = tf.contrib.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.contrib.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    clean_index = []\n",
    "    for label in range(10):\n",
    "        positive_index = list(np.where(y_train[:, label] == 1)[0])        \n",
    "        clean_index = np.append(clean_index, np.random.choice(positive_index, clean_data_size, replace=False)).astype(int)\n",
    "    \n",
    "    x_clean = x_train[clean_index]\n",
    "    y_clean = y_train[clean_index]\n",
    "    x_train = np.delete(x_train, clean_index, axis=0)\n",
    "    y_train = np.delete(y_train, clean_index, axis=0)\n",
    "    return x_train, y_train, x_test, y_test, x_clean, y_clean\n",
    "\n",
    "\n",
    "def generate_noise_labels(y_train, noise_level):\n",
    "    num_noise = int(noise_level * y_train.shape[0])\n",
    "    noise_index = np.random.choice(y_train.shape[0], num_noise, replace=False)\n",
    "    label_slice = np.argmax(y_train[noise_index], axis=1)\n",
    "    new_label = np.random.randint(low=0, high=10, size=num_noise)\n",
    "    while sum(label_slice == new_label) > 0:\n",
    "        n = sum(label_slice == new_label)\n",
    "        new_label[label_slice == new_label] = np.random.randint(low=0, high=10, size=n)\n",
    "    y_train[noise_index] = tf.contrib.keras.utils.to_categorical(new_label, 10)\n",
    "    return y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.8\n",
    "clean_data_size = 50\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_clean, y_clean = load_data(clean_data_size)\n",
    "y_train_orig = deepcopy(y_train)\n",
    "y_train = generate_noise_labels(y_train, noise_level)\n",
    "\n",
    "file_setting.write('noise level: ' + str(noise_level) + '\\n')\n",
    "file_setting.write('clean data size for each class: ' + str(clean_data_size) + '\\n')\n",
    "file_setting.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture, num_classes, learning_rate=0.001, dropout=0.5):\n",
    "    model = Sequential()\n",
    "    for layer_index in range(len(architecture)):\n",
    "        layer = architecture[layer_index]\n",
    "        if len(layer) == 3:\n",
    "            if layer_index == 0:\n",
    "                model.add(Conv2D(layer[0], kernel_size=(layer[1], layer[2]), input_shape=(32, 32, 3),\n",
    "                                 kernel_initializer='glorot_normal', activation='relu', padding='same'))\n",
    "            else:\n",
    "                model.add(Conv2D(layer[0], kernel_size=(layer[1], layer[2]), kernel_initializer='glorot_normal',\n",
    "                                 activation='relu', padding='same'))\n",
    "            if layer_index < 3:\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        elif len(layer) == 1:\n",
    "            if len(architecture[layer_index - 1]) == 3:\n",
    "                model.add(Flatten())\n",
    "            model.add(Dense(layer[0], activation='relu', kernel_initializer='glorot_normal'))\n",
    "        else:\n",
    "            print('Invalid architecture /(ㄒoㄒ)/~~')\n",
    "    model.add(Dropout(dropout))\n",
    "    if num_classes > 2:\n",
    "        model.add(Dense(num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "    elif num_classes == 2:\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', metrics=['accuracy'], optimizer=adam)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 binary classifier\n",
    "binary_classifier_list = []\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [256]]\n",
    "for label in range(10):\n",
    "    model = create_model(architecture, num_classes=2)\n",
    "    binary_classifier_list.append(model)\n",
    "\n",
    "file_setting = open(dirs + 'file_setting.txt', 'a+')\n",
    "file_setting.write('*'*10 + 'architecture of binary classifier' + '*'*10 + '\\n')\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = file_setting\n",
    "print(model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "file_setting.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 label 0\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2545 - acc: 0.4300\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 766us/step - loss: 0.2377 - acc: 0.5700\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 967us/step - loss: 0.2377 - acc: 0.5900\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2576 - acc: 0.5100\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 832us/step - loss: 0.2134 - acc: 0.6200\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.2091 - acc: 0.6300\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 744us/step - loss: 0.1699 - acc: 0.7900\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 754us/step - loss: 0.1612 - acc: 0.8100\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 777us/step - loss: 0.1800 - acc: 0.7400\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 759us/step - loss: 0.1720 - acc: 0.7600\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 854us/step - loss: 0.1534 - acc: 0.7700\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.1407 - acc: 0.8100\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.1559 - acc: 0.7900\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.8600\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 779us/step - loss: 0.1242 - acc: 0.8600\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 767us/step - loss: 0.1736 - acc: 0.7600\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 762us/step - loss: 0.1677 - acc: 0.7500\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 734us/step - loss: 0.1361 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.1351 - acc: 0.8200\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1243 - acc: 0.8500\n",
      "epoch 0 label 1\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.2555 - acc: 0.4900\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 938us/step - loss: 0.2549 - acc: 0.4600\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 888us/step - loss: 0.2504 - acc: 0.5100\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 787us/step - loss: 0.2466 - acc: 0.5600\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.2448 - acc: 0.5900\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 799us/step - loss: 0.2506 - acc: 0.4600\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.2455 - acc: 0.6200\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.2447 - acc: 0.5600\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6200\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2423 - acc: 0.5800\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.2378 - acc: 0.6500\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 741us/step - loss: 0.2330 - acc: 0.6700\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 766us/step - loss: 0.2297 - acc: 0.6300\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 747us/step - loss: 0.2273 - acc: 0.6200\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2197 - acc: 0.6300\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.2009 - acc: 0.7100\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 689us/step - loss: 0.2046 - acc: 0.7000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 715us/step - loss: 0.2028 - acc: 0.6700\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 736us/step - loss: 0.1798 - acc: 0.7400\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 998us/step - loss: 0.2015 - acc: 0.6600\n",
      "epoch 0 label 2\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2495 - acc: 0.5500\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.2549 - acc: 0.5200\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.2543 - acc: 0.5400\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 784us/step - loss: 0.2481 - acc: 0.5200\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2519 - acc: 0.5100\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.2458 - acc: 0.5000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 741us/step - loss: 0.2457 - acc: 0.5800\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 687us/step - loss: 0.2511 - acc: 0.5100\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2473 - acc: 0.5200\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.2390 - acc: 0.6300\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.2351 - acc: 0.6500\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 726us/step - loss: 0.2279 - acc: 0.6700\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 695us/step - loss: 0.2412 - acc: 0.5800\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 711us/step - loss: 0.2296 - acc: 0.6100\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 694us/step - loss: 0.2617 - acc: 0.5100\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2330 - acc: 0.6000\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 703us/step - loss: 0.2438 - acc: 0.5400\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 723us/step - loss: 0.2328 - acc: 0.6400\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 735us/step - loss: 0.2255 - acc: 0.7100\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 759us/step - loss: 0.2196 - acc: 0.7200\n",
      "epoch 0 label 3\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2460 - acc: 0.6200\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 862us/step - loss: 0.2472 - acc: 0.4900\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 892us/step - loss: 0.2483 - acc: 0.5500\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 965us/step - loss: 0.2345 - acc: 0.5700\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 766us/step - loss: 0.2533 - acc: 0.6200\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.2260 - acc: 0.5800\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 908us/step - loss: 0.2427 - acc: 0.5700\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 847us/step - loss: 0.2217 - acc: 0.6300\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.2256 - acc: 0.6500\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.2005 - acc: 0.7400\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 765us/step - loss: 0.2000 - acc: 0.6900\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 752us/step - loss: 0.2010 - acc: 0.7400\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 796us/step - loss: 0.2021 - acc: 0.6500\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 897us/step - loss: 0.1818 - acc: 0.7600\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.1727 - acc: 0.7200\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2011 - acc: 0.7000\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 746us/step - loss: 0.1697 - acc: 0.7200\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 836us/step - loss: 0.1804 - acc: 0.6900\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 742us/step - loss: 0.1746 - acc: 0.7500\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.1637 - acc: 0.7600\n",
      "epoch 0 label 4\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2578 - acc: 0.4600\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2606 - acc: 0.4800\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 941us/step - loss: 0.2510 - acc: 0.5000\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 803us/step - loss: 0.2500 - acc: 0.5200\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 794us/step - loss: 0.2492 - acc: 0.5600\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 817us/step - loss: 0.2483 - acc: 0.5500\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 811us/step - loss: 0.2465 - acc: 0.6800\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 868us/step - loss: 0.2449 - acc: 0.6200\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.2440 - acc: 0.5000\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 793us/step - loss: 0.2412 - acc: 0.5200\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 821us/step - loss: 0.2451 - acc: 0.6100\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 752us/step - loss: 0.2438 - acc: 0.6600\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 836us/step - loss: 0.2408 - acc: 0.6500\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 819us/step - loss: 0.2423 - acc: 0.5200\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 764us/step - loss: 0.2324 - acc: 0.5700\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 757us/step - loss: 0.2257 - acc: 0.5700\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 759us/step - loss: 0.2155 - acc: 0.6500\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 1000us/step - loss: 0.2030 - acc: 0.7300\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1897 - acc: 0.7600\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2019 - acc: 0.6500\n",
      "epoch 0 label 5\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2516 - acc: 0.5100\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2583 - acc: 0.4900\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2480 - acc: 0.5400\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2518 - acc: 0.5300\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2470 - acc: 0.6300\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2434 - acc: 0.6500\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2349 - acc: 0.6300\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2405 - acc: 0.5300\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2345 - acc: 0.6300\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2182 - acc: 0.7300\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2150 - acc: 0.6600\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2043 - acc: 0.6500\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1893 - acc: 0.7100\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1866 - acc: 0.7400\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1972 - acc: 0.6900\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2037 - acc: 0.6700\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1750 - acc: 0.7400\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1560 - acc: 0.8100\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - acc: 0.8100\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1347 - acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# use the idea of PU learning to augment positive data\n",
    "epochs = 5\n",
    "additional_data_index = [[] for i in range(10)]\n",
    "for epoch in range(epochs):\n",
    "    for label in range(10):\n",
    "        print('epoch', epoch, 'label', label)\n",
    "        positive_index = list(np.where(y_clean[:, label] == 1)[0])\n",
    "        x = x_clean[positive_index]\n",
    "        x = np.concatenate((x, x_train[additional_data_index[label]]), axis=0)\n",
    "        n_p = len(x)\n",
    "        n_n = min(400, n_p)\n",
    "        negative_index = list(np.where(y_clean[:, label] != 1)[0])\n",
    "        negative_index = np.random.choice(negative_index, n_n, replace=False)\n",
    "        x = np.concatenate((x, x_clean[negative_index]), axis=0)\n",
    "        y = [1] * n_p + [0] * n_n\n",
    "        classifier = binary_classifier_list[label]\n",
    "        classifier.fit(x, y, batch_size=32, epochs=20, shuffle=True)\n",
    "        pred_train = classifier.predict(x_train)\n",
    "        candidate_index = np.where(pred_train > 0.98)[0]\n",
    "        if len(candidate_index) < 1000:\n",
    "            additional_data_index[label] = list(candidate_index)\n",
    "        else:\n",
    "            additional_data_index[label] = np.argsort(-pred_train, axis=0)[0:1000].reshape(-1)\n",
    "    \n",
    "    # estimate additional clean data\n",
    "    precision_additional_data = []\n",
    "    number_additional_data = []\n",
    "    for label in range(10):\n",
    "        index = additional_data_index[label]\n",
    "        true_positive_index = list(np.where(y_train_orig[:, label] != 1)[0])\n",
    "        TP = len(list(set(index) & set(true_positive_index)))\n",
    "        precision_additional_data.append(TP/len(index))\n",
    "        number_additional_data.append(len(index))\n",
    "    print(precision_additional_data)\n",
    "    print(number_additional_data)\n",
    "\n",
    "    file_additional_data.write('iteraion ' + str(epoch) + ', precision of additional data for each class' + '\\n')\n",
    "    file_additional_data.write(str(precision_additional_data) + '\\n')\n",
    "    file_additional_data.write('iteraion ' + str(epoch) + ', number of additional data for each class' + '\\n')\n",
    "    file_additional_data.write(str(number_additional_data) + '\\n')\n",
    "file_additional_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get additional data and train teacher model\n",
    "x_add = deepcopy(x_clean)\n",
    "y_add = deepcopy(y_clean)\n",
    "for label in range(10):\n",
    "    index = additional_data_index[label]\n",
    "    x_add = np.concatenate((x_add, x_train[index]), axis=0)\n",
    "    y_add = np.concatenate((y_add, tf.contrib.keras.utils.to_categorical([label]*len(index), 10)))\n",
    "\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [500]]\n",
    "teacher_model = create_model(architecture, num_classes=10)\n",
    "\n",
    "file_setting = open(dirs + 'file_setting.txt', 'a+')\n",
    "file_setting.write('*'*10 + 'architecture of teacher classifier' + '*'*10 + '\\n')\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = file_setting\n",
    "print(teacher_model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "file_setting.close()\n",
    "\n",
    "History_teacher = teacher_model.fit(x_add, y_add, validation_data=(x_test, y_test), batch_size=64, epochs=100, shuffle=True)\n",
    "\n",
    "file_teacher.write('training accuracy' + '\\n')\n",
    "file_teacher.write(str(History_teacher.history['acc']) + '\\n')\n",
    "file_teacher.write('test accuracy' + '\\n')\n",
    "file_teacher.write(str(History_teacher.history['val_acc']) + '\\n')\n",
    "file_teacher.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate lambda\n",
    "def get_precision(x, y, model):\n",
    "    mean_precision = []\n",
    "    prediction = model.predict(x)\n",
    "    y_pred = prediction.argmax(axis=-1)\n",
    "    for label in range(10):        \n",
    "        pred_positive_index = list(np.where(y_pred == label)[0])\n",
    "        true_positive_index = list(np.where(y[:, label] != 1)[0])\n",
    "        TP = len(list(set(pred_positive_index) & set(true_positive_index)))\n",
    "        print(label, len(pred_positive_index))\n",
    "        mean_precision.append(TP/len(pred_positive_index))\n",
    "    return mean_precision\n",
    "\n",
    "precision_whole = get_precision(x_train, y_train, teacher_model)\n",
    "precision_clean = get_precision(x_clean, y_clean, teacher_model)\n",
    "lambda_teacher = sum(precision_clean) / (sum(precision_clean) + sum(precision_whole))\n",
    "print(precision_whole, precision_clean, lambda_teacher)\n",
    "\n",
    "file_additional_data = open(dirs + 'file_additional_data.txt', 'a+')\n",
    "file_additional_data.write('precision of teacher model on whole training dataset' + '\\n')\n",
    "file_additional_data.write(str(precision_whole) + '\\n')\n",
    "file_additional_data.write('precision of teacher model on clean dataset' + '\\n')\n",
    "file_additional_data.write(str(precision_clean) + '\\n')\n",
    "file_additional_data.write('lambda: ' + str(lambda_teacher) + '\\n')\n",
    "file_additional_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a multi-classifier\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [500]]\n",
    "student_model = create_model(architecture, num_classes=10)\n",
    "\n",
    "file_setting = open(dirs + 'file_setting.txt', 'a+')\n",
    "file_setting.write('*'*10 + 'architecture of student classifier' + '*'*10 + '\\n')\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = file_setting\n",
    "print(student_model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "file_setting.close()\n",
    "\n",
    "y_pred = teacher_model.predict(x_train)\n",
    "y_pseudo = lambda_teacher * y_train + (1-lambda_teacher) * y_pred\n",
    "History_student = student_model.fit(x_train, y_pseudo, validation_data=(x_test, y_test), batch_size=64, epochs=100, shuffle=True)\n",
    "\n",
    "file_student.write('training accuracy' + '\\n')\n",
    "file_student.write(str(History_student.history['acc']) + '\\n')\n",
    "file_student.write('test accuracy' + '\\n')\n",
    "file_student.write(str(History_student.history['val_acc']) + '\\n')\n",
    "file_student.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train benchmark\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [500]]\n",
    "benchmark_model = create_model(architecture, num_classes=10)\n",
    "\n",
    "file_setting = open(dirs + 'file_setting.txt', 'a+')\n",
    "file_setting.write('*'*10 + 'architecture of benchmark classifier' + '*'*10 + '\\n')\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = file_setting\n",
    "print(benchmark_model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "file_setting.close()\n",
    "\n",
    "History_benchmark = student_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=64, epochs=100, shuffle=True)\n",
    "\n",
    "file_benchmark.write('training accuracy' + '\\n')\n",
    "file_benchmark.write(str(History_benchmark.history['acc']) + '\\n')\n",
    "file_benchmark.write('test accuracy' + '\\n')\n",
    "file_benchmark.write(str(History_benchmark.history['val_acc']) + '\\n')\n",
    "file_benchmark.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
