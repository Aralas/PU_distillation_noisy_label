training accuracy
[0.49294431726956167, 0.7326468345229631, 0.7715484362172317, 0.7943363845302893, 0.8132151030202934, 0.8238939739746687, 0.8395308925394427, 0.845347063355915, 0.840865751471254, 0.8525934399856492, 0.8582189169937559, 0.8586956521739131, 0.8642257817549891, 0.8658466817858017, 0.870518688115339, 0.8714721586120483, 0.8728070174074646, 0.8824370709836801, 0.8821510297937488, 0.8779557589171589, 0.8841533180778032, 0.8879672006556862, 0.8842486650501836, 0.8925438596036578, 0.8933066362010714, 0.8909229595273801, 0.8901601831118265, 0.900648359985046, 0.9010297481928228, 0.8962623950273003, 0.8962623950727653, 0.9003623187041846, 0.8961670480549199, 0.9010297484201479, 0.9060831427301368, 0.9039855072009118, 0.904462242517464, 0.9067505719914498, 0.9058924484216557, 0.9060831427301368, 0.9046529365986199, 0.9068459190547603, 0.9098016782447094, 0.9136155606407322, 0.9097063309540737, 0.9098016780173842, 0.9079900838599507, 0.9108504958047292, 0.9112318840579711, 0.9130434783972646, 0.9118993134102141, 0.9111365369491955, 0.9118039665742288, 0.9104691075969524, 0.9153318077348553, 0.9118039664378337, 0.9127574370709383, 0.9123760487722314, 0.9142829900384404, 0.9139016019670587, 0.9155225017705462, 0.9147597253095276, 0.916094584195874, 0.9136155606861973, 0.9171434018922888, 0.9130434783972646, 0.9149504194361485, 0.9167620138209072, 0.9137109075676476, 0.9146643782916822, 0.914378337283611, 0.9146643782007522, 0.9144736842559913, 0.9147597253095276, 0.9166666668030617, 0.9143783370562858, 0.9156178491066468, 0.9171434020286839, 0.9166666666666666, 0.9161899314410444, 0.9159038902056481, 0.9193363844848242, 0.914855072372838, 0.9162852785043549, 0.9163806253858052, 0.9199084667737569, 0.916762013684512, 0.9147597254459227, 0.9212433255691732, 0.9170480548744434, 0.9163806255676653, 0.9176201372997712, 0.9164759724491157, 0.9200991610367729, 0.915903890160183, 0.9168573607478225, 0.9173340959734447, 0.9146643784735423, 0.9174294431276853, 0.9223874903743636]
test accuracy
[0.3274, 0.3495, 0.3636, 0.3708, 0.3809, 0.3612, 0.3701, 0.3559, 0.3835, 0.3769, 0.3798, 0.3767, 0.3755, 0.388, 0.377, 0.3739, 0.385, 0.3775, 0.3717, 0.3839, 0.3881, 0.3696, 0.388, 0.3805, 0.3777, 0.3759, 0.372, 0.3764, 0.3898, 0.3851, 0.3868, 0.3791, 0.3812, 0.3809, 0.3847, 0.3838, 0.3816, 0.3875, 0.3805, 0.3754, 0.3817, 0.378, 0.3806, 0.3812, 0.3662, 0.3828, 0.3844, 0.3784, 0.3848, 0.3852, 0.3794, 0.3812, 0.3869, 0.3833, 0.3689, 0.3742, 0.3772, 0.3792, 0.3845, 0.3883, 0.3799, 0.3873, 0.3797, 0.3857, 0.3866, 0.378, 0.3797, 0.3857, 0.3832, 0.3776, 0.3745, 0.3791, 0.3775, 0.3814, 0.3804, 0.3816, 0.3902, 0.3794, 0.3873, 0.3825, 0.3753, 0.3841, 0.3717, 0.3709, 0.3788, 0.3775, 0.3759, 0.3817, 0.3872, 0.3791, 0.3822, 0.3768, 0.3834, 0.3834, 0.3835, 0.3808, 0.3761, 0.3828, 0.3798, 0.3789]
