training accuracy
[0.5056129032104246, 0.7073548386942956, 0.7398709677573173, 0.7627741935330052, 0.776709677403973, 0.787741935483871, 0.8059999999846181, 0.8103225806605431, 0.8093548386942956, 0.818451612887844, 0.8203225806605431, 0.8289677419354838, 0.8275483870813923, 0.8339354838863496, 0.8373548387019865, 0.8369032257910698, 0.8448387096774194, 0.8437419354684891, 0.844967741920102, 0.8474193548387097, 0.8470322580491343, 0.8482580645161291, 0.8505806451766722, 0.857032258079898, 0.8555483870813924, 0.8543225806451613, 0.8530967742089303, 0.8591612903379625, 0.8524516129032258, 0.8583870967588118, 0.8573548387250592, 0.8603870967895754, 0.8621935483717149, 0.8593548387250592, 0.8623870967741936, 0.866451612887844, 0.8620000000153818, 0.866, 0.8616129032411883, 0.8658064516282851, 0.8658709677573173, 0.8681935483870967, 0.8663870967741936, 0.8667096774347367, 0.8676129032411883, 0.867741935483871, 0.8732258064669948, 0.865225806436231, 0.8650322580798979, 0.8709677419201021, 0.8717419354992528, 0.8736774193548387, 0.8711612903225806, 0.8673548387096774, 0.8706451613057045, 0.8701935483870967, 0.8706451613057045, 0.8721290322580645, 0.8716129032104246, 0.8688387096774194, 0.8691612903225806, 0.874064516144414, 0.8720645161290322, 0.8681935483717149, 0.8741290322734464, 0.8731612903071988, 0.8714838709523601, 0.8739354838863496, 0.8696129032411883, 0.8752903225652633, 0.8738709677419355, 0.8709032258064516, 0.8727741935483871, 0.8741290322580645, 0.8718709677265536, 0.873548387112156, 0.8729677419508657, 0.8733548387250593, 0.8712903225652633, 0.8736774193394569, 0.8700645161444142, 0.8702580645161291, 0.8740645161136504, 0.874709677403973, 0.8716774193394569, 0.875290322596027, 0.8733548386942955, 0.8754838709831237, 0.8776129032411883, 0.8739999999846182, 0.8751612903379625, 0.8740645161290322, 0.8745806451459085, 0.8718064516282851, 0.876774193563769, 0.8727741935330052, 0.8733548387250593, 0.8747096774347367, 0.8738064515975213, 0.8763870967895754]
test accuracy
[0.3163, 0.3301, 0.3341, 0.3611, 0.3493, 0.3466, 0.3439, 0.3636, 0.3723, 0.3694, 0.3589, 0.3708, 0.3676, 0.3592, 0.3479, 0.3642, 0.3634, 0.3732, 0.3598, 0.3584, 0.3651, 0.3696, 0.3627, 0.3741, 0.3619, 0.3558, 0.3726, 0.3647, 0.3708, 0.3606, 0.3719, 0.3717, 0.3695, 0.3642, 0.3692, 0.3765, 0.3707, 0.375, 0.3677, 0.3632, 0.3645, 0.3634, 0.3722, 0.3729, 0.3677, 0.3674, 0.3729, 0.3798, 0.3687, 0.3709, 0.3746, 0.3739, 0.362, 0.3686, 0.3692, 0.3753, 0.3708, 0.37, 0.3617, 0.3706, 0.3718, 0.3717, 0.3726, 0.3671, 0.3674, 0.3721, 0.3728, 0.3757, 0.3573, 0.3711, 0.3718, 0.3709, 0.372, 0.3702, 0.3655, 0.3702, 0.3646, 0.372, 0.3663, 0.3662, 0.3723, 0.3674, 0.367, 0.3631, 0.3761, 0.3708, 0.3772, 0.383, 0.3744, 0.3723, 0.3658, 0.365, 0.3681, 0.3671, 0.3693, 0.3767, 0.3731, 0.379, 0.3682, 0.3742]
