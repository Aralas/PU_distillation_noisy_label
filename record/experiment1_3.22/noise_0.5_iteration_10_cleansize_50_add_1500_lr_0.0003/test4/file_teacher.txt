training accuracy
[0.5124516129186076, 0.6974193548387096, 0.738, 0.7601935483870967, 0.774709677403973, 0.7825806451459085, 0.7920000000153818, 0.800193548371715, 0.8049032257910698, 0.8076129032258065, 0.8088387096620375, 0.8178709677419355, 0.8232903225806452, 0.825290322596027, 0.827032258079898, 0.828967741920102, 0.828258064516129, 0.8325806451766722, 0.8342580645007472, 0.8321935484024786, 0.8374193548540915, 0.8429677419354838, 0.8421290322426827, 0.8426451612903226, 0.8431612903379625, 0.8406451612749407, 0.8479354838709677, 0.8469677419354839, 0.8463870967895754, 0.8451612903071988, 0.85051612904764, 0.850967741920102, 0.8508387096620376, 0.8497419354684891, 0.8531612903071988, 0.856516129032258, 0.8550322580491343, 0.8569677419354839, 0.856709677403973, 0.8580645161136504, 0.8562580645007472, 0.859032258079898, 0.8567096774193549, 0.8575483870813924, 0.8556129032104246, 0.8609032257910698, 0.8581290322580645, 0.8608387096774194, 0.859225806451613, 0.8561935483717149, 0.8636774193394569, 0.858451612887844, 0.8581290322580645, 0.8619354838555859, 0.8615483871121561, 0.8639354838863496, 0.8636129032104246, 0.863225806451613, 0.8604516129032258, 0.8615483871121561, 0.8603225806451613, 0.8643870967895754, 0.8642580645315109, 0.8650967742089303, 0.8649032258064516, 0.8631612903379625, 0.8625806451766722, 0.8610967742089303, 0.8654193548233279, 0.8643225806297794, 0.8616129032411883, 0.8650967741935484, 0.8665161290476399, 0.8659354838863496, 0.8654193548387097, 0.863225806436231, 0.8656774193702206, 0.8640645161444142, 0.8649032258064516, 0.8659999999846182, 0.8663870967895754, 0.8677419354992528, 0.8631612903225806, 0.8676774193394569, 0.8648387096774194, 0.8669677419508657, 0.8615483871121561, 0.8642580645161291, 0.8648387096928012, 0.8667741935330052, 0.8652258064669948, 0.8639999999846182, 0.8636774193548387, 0.8667741935483871, 0.8639354838709677, 0.8690322580491343, 0.8636129032411883, 0.8665161290168762, 0.8634838709677419, 0.866451612887844]
test accuracy
[0.3365, 0.3535, 0.3596, 0.3491, 0.3593, 0.3563, 0.3663, 0.3468, 0.352, 0.3545, 0.3692, 0.365, 0.3633, 0.3675, 0.3696, 0.368, 0.364, 0.3756, 0.3739, 0.3649, 0.3541, 0.3607, 0.3709, 0.3751, 0.361, 0.3651, 0.366, 0.3669, 0.3677, 0.3691, 0.3741, 0.373, 0.3588, 0.3724, 0.3619, 0.3771, 0.3658, 0.3643, 0.3639, 0.3739, 0.3613, 0.3638, 0.3749, 0.3678, 0.3702, 0.3737, 0.3615, 0.368, 0.3705, 0.3702, 0.3647, 0.373, 0.3694, 0.3639, 0.3738, 0.359, 0.3696, 0.3663, 0.3675, 0.3728, 0.3736, 0.3707, 0.3712, 0.3688, 0.3603, 0.3677, 0.3632, 0.3611, 0.3677, 0.3643, 0.3605, 0.3719, 0.3646, 0.3668, 0.365, 0.3678, 0.3647, 0.3733, 0.3713, 0.3748, 0.3691, 0.369, 0.3616, 0.3559, 0.3701, 0.3632, 0.3641, 0.3606, 0.3773, 0.369, 0.3603, 0.3649, 0.3696, 0.3671, 0.3595, 0.3631, 0.3672, 0.3662, 0.3609, 0.3613]
