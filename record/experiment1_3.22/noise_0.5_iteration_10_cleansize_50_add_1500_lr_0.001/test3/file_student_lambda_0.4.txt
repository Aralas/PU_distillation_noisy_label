training accuracy
[0.35159595959355133, 0.41670707070466245, 0.4329898989826742, 0.4473737373785539, 0.45608080807358325, 0.4596363636363636, 0.46868686868205217, 0.4792929292832962, 0.4844040404040404, 0.4910303030351196, 0.49844444444444447, 0.5056565656710152, 0.5094141414045084, 0.517959595959596, 0.5248080808225304, 0.5291515151539234, 0.5332525252380756, 0.536464646469463, 0.5396565656710153, 0.5469898989947155, 0.5483636363660447, 0.5536363636315471, 0.5602020202020203, 0.5613939393867146, 0.5635353535257205, 0.5668282828379159, 0.5693333333333334, 0.569555555550739, 0.5694949494877247, 0.5748080808225304, 0.577050505040872, 0.5796565656613822, 0.5798383838335673, 0.5804040403968156, 0.5868484848581179, 0.5831313131264966, 0.5849696969841466, 0.5880404040355875, 0.5867878787782457, 0.5846464646609143, 0.5914343434198939, 0.5911313131216801, 0.590828282821058, 0.5932727272871768, 0.5919797979749815, 0.5918989898893569, 0.5928282828282828, 0.5937979797931633, 0.5943434343386178, 0.594989898989899, 0.5918585858682189, 0.5976767676719511, 0.5965252525397021, 0.5952929292832962, 0.5971313131264966, 0.6015151515151516, 0.5968484848508931, 0.5934949494901329, 0.599090909081276, 0.5957575757720254, 0.5965454545454546, 0.5971919191871027, 0.598505050509867, 0.5999191919047423, 0.5978989898941733, 0.6037373737325572, 0.5971717171669007, 0.6005858585810421, 0.5975151515151516, 0.5992929292832962, 0.5983838383934714, 0.6008484848484849, 0.598565656551207, 0.5996767676815842, 0.6003636363636363, 0.5956969697017862, 0.6006262626310792, 0.5998181818326315, 0.5997979798027964, 0.5986868686796439, 0.5997373737301489, 0.5986464646464646, 0.6010505050601381, 0.5974343434487931, 0.6040606060750556, 0.60103030302067, 0.5998787878787879, 0.6011515151466986, 0.6026060606108772, 0.6012525252573417, 0.6016161616209782, 0.600040404040404, 0.6032323232275068, 0.6035959595863265, 0.6035353535498031, 0.602666666669075, 0.6001212121356617, 0.5974545454497289, 0.6026666666666667, 0.6026666666594419]
test accuracy
[0.346, 0.3711, 0.364, 0.3678, 0.3758, 0.3756, 0.3735, 0.376, 0.3869, 0.3773, 0.3744, 0.3839, 0.3799, 0.3794, 0.3817, 0.3751, 0.3775, 0.3733, 0.3705, 0.3666, 0.3676, 0.374, 0.3666, 0.371, 0.3713, 0.3646, 0.3699, 0.3684, 0.3662, 0.3547, 0.3698, 0.3693, 0.3653, 0.364, 0.359, 0.3573, 0.3606, 0.3627, 0.3643, 0.3644, 0.3598, 0.3581, 0.3549, 0.3563, 0.3608, 0.3533, 0.3609, 0.3594, 0.3579, 0.3586, 0.3626, 0.3555, 0.3542, 0.3532, 0.3544, 0.3519, 0.3637, 0.3596, 0.3577, 0.353, 0.3476, 0.3561, 0.3489, 0.353, 0.3543, 0.3524, 0.3536, 0.3481, 0.3533, 0.3493, 0.3554, 0.3474, 0.3554, 0.3532, 0.3486, 0.3519, 0.3498, 0.347, 0.3543, 0.3476, 0.3489, 0.3493, 0.3433, 0.3523, 0.3502, 0.3509, 0.3496, 0.3478, 0.3492, 0.3471, 0.3509, 0.3453, 0.3504, 0.3482, 0.3484, 0.3414, 0.3477, 0.3514, 0.3527, 0.3489]
