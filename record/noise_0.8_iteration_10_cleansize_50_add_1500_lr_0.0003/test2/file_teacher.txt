training accuracy
[0.5139999999846182, 0.7101935484024786, 0.7509677419354839, 0.770258064516129, 0.7836129032411883, 0.7927741935330053, 0.802451612887844, 0.8039354838709677, 0.8143870967741935, 0.8152258064669947, 0.8218064516129032, 0.823548387112156, 0.8268387096928012, 0.8319354838555859, 0.8309032258218334, 0.8350967742089302, 0.8355483871121561, 0.840516129032258, 0.8410967742089303, 0.8447096774193549, 0.8437419354992528, 0.8449032258064516, 0.8490967741935483, 0.8516774193394568, 0.84851612904764, 0.8502580645007471, 0.8518709677573173, 0.8552258064669948, 0.8531612903225806, 0.8544516129032258, 0.8570322580645161, 0.8578064516129033, 0.8558709677573173, 0.8584516129186076, 0.8582580645315109, 0.859032258079898, 0.8597419354684891, 0.8601935483870968, 0.8607741935330052, 0.8624516129032258, 0.8634838709831237, 0.8640645161444142, 0.8636129032258064, 0.8630967742089303, 0.8667741935483871, 0.8616129032258064, 0.8672903225806452, 0.8629677419508657, 0.8644516129186076, 0.8663870967741936, 0.867290322596027, 0.8667096774193548, 0.8662580645007472, 0.8668387096928012, 0.8693548386942955, 0.8707096774347367, 0.8703225806605431, 0.8673548386942955, 0.8687741935330052, 0.8710967741935484, 0.8672903225806452, 0.8742580645007472, 0.8683225806605431, 0.8696129032258064, 0.8697419354992528, 0.8685161290168762, 0.8705161290168763, 0.8705161290476399, 0.8686451612749407, 0.8699354838709678, 0.8690322580491343, 0.8700645161444142, 0.8722580645007472, 0.8740645161136504, 0.8701290322426827, 0.8682580645315109, 0.8712258064516128, 0.8670967742089303, 0.8737419354838709, 0.8737419354684891, 0.8701935484024786, 0.8721935484024786, 0.8695483870967742, 0.869290322596027, 0.8732903225652633, 0.8704516129186076, 0.8738709677573173, 0.8711612903225806, 0.873548387112156, 0.874064516144414, 0.8739354838863496, 0.8723225806451613, 0.8708387096928012, 0.8751612903379625, 0.8730967742089303, 0.8696129032258064, 0.8723870967895754, 0.8720645161136504, 0.872064516144414, 0.8699354838863496]
test accuracy
[0.3211, 0.3305, 0.365, 0.371, 0.3483, 0.3443, 0.357, 0.3638, 0.3687, 0.3701, 0.3592, 0.3778, 0.3709, 0.3718, 0.3774, 0.367, 0.3583, 0.3675, 0.3671, 0.3674, 0.3607, 0.3687, 0.3764, 0.3681, 0.3704, 0.3692, 0.3662, 0.3769, 0.3779, 0.3809, 0.3723, 0.3673, 0.3784, 0.3659, 0.372, 0.3704, 0.3714, 0.3739, 0.3738, 0.3743, 0.3676, 0.3724, 0.3679, 0.3689, 0.375, 0.3669, 0.3731, 0.3664, 0.3752, 0.3794, 0.3553, 0.377, 0.3706, 0.3743, 0.3715, 0.36, 0.38, 0.3664, 0.3735, 0.3749, 0.3747, 0.3696, 0.3733, 0.3742, 0.3752, 0.3763, 0.3734, 0.3587, 0.3672, 0.3747, 0.3782, 0.3662, 0.3731, 0.3735, 0.3743, 0.3672, 0.3672, 0.3614, 0.376, 0.3703, 0.3735, 0.3716, 0.3749, 0.3754, 0.376, 0.3738, 0.3712, 0.3713, 0.3742, 0.3717, 0.379, 0.3745, 0.3691, 0.373, 0.3715, 0.3706, 0.3698, 0.3693, 0.3717, 0.3739]
