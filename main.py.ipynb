{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "# from copy import deepcopy\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import functools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from CIFAR10\n",
    "def load_data(clean_data_size):\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "\n",
    "    # transform labels to one-hot vectors\n",
    "    y_train = tf.contrib.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.contrib.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    clean_index = []\n",
    "    for label in range(10):\n",
    "        positive_index = list(np.where(y_train[:, label] == 1)[0])        \n",
    "        clean_index = np.append(clean_index, np.random.choice(positive_index, clean_data_size, replace=False)).astype(int)\n",
    "    \n",
    "    x_clean = x_train[clean_index]\n",
    "    y_clean = y_train[clean_index]\n",
    "    x_train = np.delete(x_train, clean_index, axis=0)\n",
    "    y_train = np.delete(y_train, clean_index, axis=0)\n",
    "    return x_train, y_train, x_test, y_test, x_clean, y_clean\n",
    "\n",
    "\n",
    "def generate_noise_labels(y_train, noise_level):\n",
    "    num_noise = int(noise_level * y_train.shape[0])\n",
    "    noise_index = np.random.choice(y_train.shape[0], num_noise, replace=False)\n",
    "    label_slice = np.argmax(y_train[noise_index], axis=1)\n",
    "    new_label = np.random.randint(low=0, high=10, size=num_noise)\n",
    "    while sum(label_slice == new_label) > 0:\n",
    "        n = sum(label_slice == new_label)\n",
    "        new_label[label_slice == new_label] = np.random.randint(low=0, high=10, size=n)\n",
    "    y_train[noise_index] = tf.contrib.keras.utils.to_categorical(new_label, 10)\n",
    "    return y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.8\n",
    "clean_data_size = 50\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_clean, y_clean = load_data(clean_data_size)\n",
    "y_train = generate_noise_labels(y_train, noise_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture, num_classes, learning_rate=0.0002, dropout=0.5):\n",
    "    model = Sequential()\n",
    "    for layer_index in range(len(architecture)):\n",
    "        layer = architecture[layer_index]\n",
    "        if len(layer) == 3:\n",
    "            if layer_index == 0:\n",
    "                model.add(Conv2D(layer[0], kernel_size=(layer[1], layer[2]), input_shape=(32, 32, 3),\n",
    "                                 kernel_initializer='glorot_normal', activation='relu', padding='same'))\n",
    "            else:\n",
    "                model.add(Conv2D(layer[0], kernel_size=(layer[1], layer[2]), kernel_initializer='glorot_normal',\n",
    "                                 activation='relu', padding='same'))\n",
    "            if layer_index < 3:\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        elif len(layer) == 1:\n",
    "            if len(architecture[layer_index - 1]) == 3:\n",
    "                model.add(Flatten())\n",
    "            model.add(Dense(layer[0], activation='relu', kernel_initializer='glorot_normal'))\n",
    "        else:\n",
    "            print('Invalid architecture /(ㄒoㄒ)/~~')\n",
    "    model.add(Dropout(dropout))\n",
    "    if num_classes > 2:\n",
    "        model.add(Dense(num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "    elif num_classes == 2:\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', metrics=['accuracy'], optimizer=adam)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 16, 16, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 8, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 185,281\n",
      "Trainable params: 185,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generate 10 binary classifier\n",
    "binary_classifier_list = []\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [256]]\n",
    "for label in range(10):\n",
    "    model = create_model(architecture, num_classes=2)\n",
    "    binary_classifier_list.append(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.2590 - acc: 0.4100\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2549 - acc: 0.4500\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2476 - acc: 0.4800\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2470 - acc: 0.4900\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.5500\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2432 - acc: 0.6200\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.6700\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2298 - acc: 0.7500\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2265 - acc: 0.6900\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2239 - acc: 0.7600\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2076 - acc: 0.7800\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2072 - acc: 0.7600\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1961 - acc: 0.7300\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1992 - acc: 0.6700\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1945 - acc: 0.7300\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1930 - acc: 0.7300\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1894 - acc: 0.7000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1810 - acc: 0.7600\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1758 - acc: 0.7700\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1735 - acc: 0.7400\n"
     ]
    }
   ],
   "source": [
    "# use the idea of PU learning to augment positive data\n",
    "epochs = 20\n",
    "additional_data_index = [[] for i in range(10)]\n",
    "for epoch in range(epochs):\n",
    "    for label in range(10):\n",
    "        positive_index = list(np.where(y_clean[:, label] == 1)[0])\n",
    "        x = x_clean[positive_index]\n",
    "        x = np.concatenate((x, x_train[additional_data_index[label]]), axis=0)\n",
    "        n_p = len(x)\n",
    "        n_n = min(400, n_p)\n",
    "        negative_index = list(np.where(y_clean[:, label] != 1)[0])\n",
    "        negative_index = np.random.choice(negative_index, n_n, replace=False)\n",
    "        x = np.concatenate((x, x_clean[negative_index]), axis=0)\n",
    "        y = [1] * n_p + [0] * n_n\n",
    "        classifier = binary_classifier_list[label]\n",
    "        classifier.fit(x, y, batch_size=32, epochs=20, shuffle=True)\n",
    "        pred_train = classifier.predict(x_train)\n",
    "        candidate_index = np.where(pred_train > 0.98)[0]\n",
    "        if len(candidate_index) < 1000:\n",
    "            additional_data_index[label] = list(candidate_index)\n",
    "        else:\n",
    "            additional_data_index[label] = np.argsort(-pred_train, axis=0)[0:1000].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get additional data and train teacher model\n",
    "for label in range(10):\n",
    "    index = additional_data_index[label]\n",
    "    x_clean = np.concatenate((x_clean, x_train[index]), axis=0)\n",
    "    y_clean = np.concatenate((y_clean, tf.contrib.keras.utils.to_categorical([label]*len(index), 10)))\n",
    "\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [500]]\n",
    "teacher_model = create_model(architecture, num_classes=10)\n",
    "teacher_model.fit(x_clean, y_clean, batch_size=64, epochs=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a multi-classifier\n",
    "architecture = [[32, 5, 5], [32, 5, 5], [32, 5, 5], [500]]\n",
    "student_model = create_model(architecture, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
