training accuracy
[0.4873563220217767, 0.7421455940981021, 0.8084291182258577, 0.8249042147877572, 0.8448275856588079, 0.8570881224683418, 0.8800766286722088, 0.888122605638029, 0.8892720309710594, 0.9030651339625947, 0.9122605366725117, 0.9172413791733226, 0.9157088121235142, 0.9325670493973626, 0.934099616401497, 0.9444444447641629, 0.9505747125980041, 0.9528735631727168, 0.9578544057192017, 0.9613026819466631, 0.9574712647332085, 0.9716475091674776, 0.9693486585927649, 0.9724137926923817, 0.9750957858060055, 0.973563218756197, 0.9816091957676913, 0.9747126436781609, 0.9796934869554308, 0.9793103448275862, 0.980459770480335, 0.9839080463424039, 0.9827586210550476, 0.980459769703876, 0.9819923375301434, 0.9816091949912323, 0.9827586206896551]
test accuracy
[0.2718, 0.3078, 0.3281, 0.3289, 0.3515, 0.3619, 0.3637, 0.3561, 0.3652, 0.3645, 0.37, 0.3667, 0.3653, 0.3818, 0.3808, 0.3739, 0.3749, 0.3742, 0.3738, 0.3726, 0.378, 0.3737, 0.3746, 0.378, 0.3798, 0.3783, 0.3708, 0.3759, 0.3742, 0.3735, 0.3773, 0.3742, 0.3774, 0.3683, 0.3796, 0.3779, 0.3785]
training accuracy
[0.4859363435375346, 0.7453737972313876, 0.7912657290895633, 0.819763138504226, 0.850481125136643, 0.860103627031243, 0.8700962250626237, 0.8849000739310072, 0.8878608436870363, 0.8889711325385674, 0.904515173812869, 0.9137675794383316, 0.9278312359890348, 0.9285714284390718, 0.9348630643967432, 0.9356032567144235, 0.939674315189627, 0.9526276830652747, 0.9537379718726869, 0.9511472983416763, 0.9615099924657188, 0.9603997037906633, 0.9622501850481125, 0.9629903775422685, 0.9648408586232421, 0.9670614358409964, 0.9637305699481865, 0.9711324943161999, 0.9666913397483345, 0.9726128793927495, 0.9722427829912554, 0.9707623982235382, 0.9729829755736491, 0.9740932641163479, 0.9711324943603188, 0.9733530717104298, 0.9733530717986677, 0.9740932642487047]
test accuracy
[0.2636, 0.3212, 0.3283, 0.3393, 0.3485, 0.3486, 0.3504, 0.3593, 0.3645, 0.3579, 0.358, 0.3635, 0.3695, 0.3661, 0.3572, 0.3709, 0.3659, 0.3583, 0.3667, 0.3762, 0.3668, 0.3681, 0.3666, 0.3639, 0.372, 0.3708, 0.362, 0.3688, 0.3695, 0.3768, 0.3714, 0.3639, 0.3631, 0.3585, 0.3732, 0.3651, 0.368, 0.3661]
