training accuracy
[0.10505050505170918, 0.11032323232503853, 0.11872727272968099, 0.1241414141438224, 0.1298181818181818, 0.13985858585979, 0.15309090909090908, 0.16719191919252127, 0.18117171717262026, 0.19965656566379048, 0.22210101009860184, 0.2461616161592079, 0.2752525252477087, 0.3015555555603721, 0.329555555550739, 0.3594343434415682, 0.3908686868735034, 0.4172929293073789, 0.45098989898508246, 0.4799191919191919, 0.5025656565656565, 0.5309494949470867, 0.5588484848484848, 0.5776363636267305, 0.6009494949446784, 0.6248282828282828, 0.6408888888937054, 0.6552929293073789, 0.6750101010245506, 0.6960202020250186, 0.7029898989754494, 0.7156767676815842, 0.7302828282780117, 0.7458383838528334, 0.7498383838432003, 0.763010101000468, 0.7767070706926211, 0.7800000000144496, 0.7848080807984478, 0.7958787878691548, 0.8052525252573418, 0.8072525252669749, 0.8132121212024881, 0.8198383838383838, 0.8235959596007761, 0.8290707070707071, 0.8387676767532272, 0.8325252525156195, 0.8455555555651886, 0.8470707070851566, 0.8472525252380756, 0.8577575757431262, 0.860484848489665, 0.8623030302885807, 0.8654949495045826, 0.8647878787830623, 0.8726868687013183, 0.8728484848436683, 0.872121212111579, 0.8704444444299948, 0.8807272727320893, 0.8807878787830623, 0.8832323232275067, 0.8872929292784797, 0.8913939393987559, 0.8874747474699309, 0.8906464646560978, 0.8934343434439765, 0.8937171717027221, 0.8963636363491867, 0.8946060606205102, 0.9005454545454545, 0.8951313131168636, 0.9091111111159277, 0.9050909090957256, 0.9066666666522171, 0.9066868686916852, 0.9048686868542373, 0.9065050505098671, 0.9112323232419564, 0.9113333333188838, 0.9462626262722593, 0.960363636378086, 0.9686262626262626, 0.9700606060702391, 0.9744646464501968, 0.9726666666762998, 0.977979797989431, 0.9803030303030303, 0.9785050505146836, 0.978929292929293, 0.9813535353390858, 0.9813333333188837, 0.9816565656565657, 0.9831111110966615, 0.9827272727369059, 0.9834545454545455, 0.9857171717171718, 0.9833939393939394, 0.9836767676767677, 0.9854747474747475, 0.9847070707070708, 0.9858585858585859, 0.9841818181818182, 0.9843030303030303, 0.985676767662318, 0.9862222222077726, 0.9879999999855504, 0.9864242424242424, 0.9878181818181818, 0.9877979797979798, 0.9875757575757576, 0.9884848484944816, 0.9872727272727273, 0.9873939393939394, 0.9875757575757576, 0.9875151515247846, 0.9889292929292929, 0.9893939393939394, 0.9886060606060606, 0.9885050504906009, 0.9893737373737373, 0.9888888888888889, 0.9889494949494949, 0.9901818181914512, 0.990040404040404, 0.9898585858489528, 0.9915757575757576, 0.9896767676767677, 0.9905656565656565, 0.9895959595911431, 0.9908686868831365, 0.9901818181818182, 0.9903636363636363, 0.9904444444540775, 0.9907070707070708, 0.9917373737373737, 0.9899191919191919, 0.9889292929292929, 0.9903636363636363, 0.9895555555555555, 0.9902424242424243, 0.9912727272727273, 0.9917575757575757, 0.9907272727272727, 0.9897979797979798, 0.9911515151515151, 0.9911515151370656, 0.9905050505050506, 0.992, 0.9910505050505051, 0.9911717171717171, 0.9917777777633282, 0.9918585858585859, 0.9917979798076129, 0.991979797989431, 0.9917777777777778, 0.9897373737421903, 0.9918181818181818, 0.991555555550739, 0.9917373737229241, 0.9908888888888889, 0.9902828282828283, 0.9908484848484849, 0.9906868686868687, 0.9906060606060606, 0.9915151515151515, 0.9916363636363636, 0.990040404040404, 0.9923434343434343, 0.9917171717171717, 0.9902020202020202, 0.991010101010101, 0.9907070707070708, 0.9910707070707071, 0.991373737388187, 0.9921212121212121, 0.990989898989899, 0.9923838383934714, 0.9913939394035725, 0.9915353535449866, 0.9903838383838384, 0.9929696969648805, 0.9910909091005422, 0.9922222222222222, 0.9911313131264966, 0.9905252525252525, 0.9914949494949495, 0.9910101010052845, 0.9903030303126634, 0.9912121212121212, 0.9911313131313131, 0.9918787878787879, 0.9904646464646465, 0.9913333333333333, 0.9912525252525253, 0.9904242424242424, 0.991979797979798, 0.9918383838480169, 0.9917575757672088]
test accuracy
[0.1765, 0.1672, 0.1892, 0.2113, 0.2068, 0.2001, 0.2192, 0.181, 0.1783, 0.1414, 0.1518, 0.1621, 0.1481, 0.1321, 0.1206, 0.148, 0.1278, 0.1194, 0.1262, 0.1201, 0.1188, 0.1253, 0.118, 0.1345, 0.1326, 0.1241, 0.117, 0.1083, 0.131, 0.121, 0.1218, 0.1227, 0.121, 0.1199, 0.125, 0.133, 0.1143, 0.1274, 0.1217, 0.1255, 0.1143, 0.1263, 0.1176, 0.1266, 0.1268, 0.1089, 0.1192, 0.1172, 0.1262, 0.1265, 0.1179, 0.1228, 0.127, 0.1093, 0.1262, 0.118, 0.1266, 0.1243, 0.1225, 0.1089, 0.1218, 0.1235, 0.1238, 0.1147, 0.1234, 0.1194, 0.1121, 0.1175, 0.1171, 0.1167, 0.124, 0.1224, 0.1187, 0.1282, 0.1175, 0.1227, 0.1167, 0.1108, 0.126, 0.1245, 0.1232, 0.1266, 0.1252, 0.1246, 0.1291, 0.1275, 0.1295, 0.1266, 0.1275, 0.1289, 0.1258, 0.1282, 0.1299, 0.1294, 0.1276, 0.1267, 0.129, 0.1252, 0.128, 0.1287, 0.1244, 0.1256, 0.1271, 0.1292, 0.1256, 0.1246, 0.1274, 0.1291, 0.1265, 0.1246, 0.1265, 0.1272, 0.1244, 0.1237, 0.1259, 0.1249, 0.127, 0.1296, 0.1253, 0.1198, 0.1282, 0.1275, 0.1278, 0.1258, 0.1246, 0.1266, 0.1282, 0.1279, 0.1256, 0.1261, 0.1256, 0.126, 0.1261, 0.127, 0.127, 0.1249, 0.127, 0.1267, 0.1263, 0.1284, 0.1255, 0.1253, 0.1252, 0.1254, 0.1259, 0.1288, 0.1262, 0.1247, 0.1266, 0.1233, 0.125, 0.1265, 0.1281, 0.126, 0.1271, 0.1278, 0.1259, 0.1269, 0.1274, 0.1277, 0.127, 0.1265, 0.1273, 0.1275, 0.1271, 0.1261, 0.1269, 0.1257, 0.1266, 0.1266, 0.1275, 0.1271, 0.1264, 0.1263, 0.1287, 0.1267, 0.1279, 0.1264, 0.1283, 0.1269, 0.1279, 0.1271, 0.1259, 0.1249, 0.1264, 0.1269, 0.1274, 0.128, 0.1277, 0.1265, 0.1274, 0.1268, 0.1273, 0.1259, 0.1265, 0.1261, 0.1261, 0.1271, 0.1262, 0.1259]
